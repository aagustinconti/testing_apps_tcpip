{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introducci\u00f3n","text":""},{"location":"#que-buscamos-hacer","title":"\u00bfQu\u00e9 buscamos hacer?","text":"<p>Este proyecto se centra en el desarrollo de una aplicaci\u00f3n (API) que permite realizar operaciones CRUD en una base de datos MySQL. El objetivo principal es utilizar los endpoints de la API para realizar pruebas de rendimiento.</p> <p>Adem\u00e1s, exploraremos y evaluaremos diversas herramientas para realizar pruebas, como k6, y la implementaci\u00f3n de Grafana para la visualizaci\u00f3n de los resultados obtenidos.</p>"},{"location":"2-body/","title":"API &amp; UI","text":""},{"location":"2-body/#contexto","title":"Contexto","text":"<p>En esta parte del desarrollo nos dedicamos a desarrollar una API CRUD con FAST API usando python. El objetivo principal de esta API es un sistema de control de stock para negocios, con capacidad de crear y contener usuarios. Tambi\u00e9n, el agregado de los productos en stock, con sus caracter\u00edsticas, entre ellas, nombre, c\u00f3digo, precio, cantidad, descripci\u00f3n e imagen ilustrativa, la cual es subida a trav\u00e9s de la API.</p> <p>Adem\u00e1s en esta instancia se tom\u00f3 la decisi\u00f3n de la base de datos a usar, considerando el entorno de producci\u00f3n, al ser Kubernetes terminamos optando por MySQL, por facilidad de desplegar y para interactuar con la base de datos se utiliz\u00f3 el ORM SQLAlchemy.</p> <p>Por \u00faltimo, desarroll\u00f3 una interfaz de usuario (UI) basada en NODE JS, haciendo uso del framework Next JS, el cual permite el uso de componentes de React para generar aplicaciones multi p\u00e1gina. A trav\u00e9s de esta interfaz gr\u00e1fica, el usuario ser\u00e1 capaz de:</p> <ul> <li>Observar todos los productos registrados en la base de datos y filtrar por c\u00f3digo o nombre de producto a trav\u00e9s de una barra de b\u00fasqueda.</li> <li>En caso de estar registrado como operador del sistema, se podr\u00e1 acceder a un panel de administraci\u00f3n.</li> <li>A trav\u00e9s del panel de administraci\u00f3n, ser\u00e1 posible agregar, editar o borrar productos. Al momento de editar o agregar un producto se podr\u00e1 subir una im\u00e1gen ilustrativa del mismo.</li> <li>No se posee una interfaz de registro, estos se deberan hacer via API con ayuda de algun desarollador.</li> <li>Cabe destacar que cada usuario tendra productos asociados a el, no podra ver ni operar sobre productos de otros usuarios en el panel de administracion.</li> </ul> <p>Para la etapa de desarrollo local, se utiliz\u00f3 Docker como herramienta de contenerizaci\u00f3n, que permite luego subir im\u00e1genes al Docker Hub. A trav\u00e9s de la herramienta Docker Compose, la cual permiti\u00f3 simular un ambiente parecido al de producci\u00f3n.  </p>"},{"location":"2-body/#como-generar-el-ambiente-de-desarrollo-local","title":"Como generar el ambiente de desarrollo local","text":"<p>Como primer paso, se debe tener instalado poetry y nodejs.</p> <p>Primero, se deben instalar las dependencias de python con poetry.</p> <pre><code>poetry install\n</code></pre> <p>Luego se debe igresar a la carpeta de la ui e instalar las dependencias de nodejs</p> <pre><code>cd ./ui\nnpm install\n</code></pre> <p>Para ejecutar la aplicacion hace falta poseer docker instalado en el equipo, ademas se debe crear una copia de <code>.env.sample</code> y renombrarla como <code>.env</code> para que docker sea capaz de cargar las configuraciones.</p> <p>Una vez realizado esto, para ejecutar el proyeco, se debe usar:</p> <pre><code>docker compose up -d --build\n ```\n\nEsto levantara la base de datos (MySQL), la API y la (UI).\n\nEl tag `--build` fuerza a que al inicio del despliegue se re cree la imagen de la API y UI. No seria necesario en un simple reinicio.\n\nPara parar la infraestructura se debe usar:\n\n```bash\ndocker compose down\n</code></pre> <p>En caso de querer correr en modo desarollo, se debe iniciar el deploy y luego utilizar:</p> <pre><code>docker compose down api\n# 0\ndocker compose down ui\n</code></pre> <p>El comando a seleccionar dependera de en que entorno se deba trabajar, dado que el primero da de baja el contenedor de API y el segundo el de la UI.</p> <p>Para correr la API en modo desarollo se puede hacer uso de los sugientes comandos:</p> <pre><code># Usando poetry\npoetry run uvicorn app.main:app --reload\n\n# o si la terminal ya se encuentra en el entorno virtual\nuvicorn app.main:app --reload\n</code></pre> <p>Y en el caso de la UI dentro de la carpeta ui:</p> <pre><code>npm run dev\n</code></pre>"},{"location":"2-body/#estructura","title":"Estructura","text":"<p>El proyecto, este se organiza internamente por carpetas:</p> <p>La carpeta <code>app</code> contiene todo lo referente a la API, y se compone de las subcarpetas:</p> <ul> <li><code>api</code>: Contiene toda la logica corespondiente a las rutas de la API (Definicion de endpoints).</li> <li><code>core</code>: Contiene utilidades generales al protecto de la API, como configuraciones globales.</li> <li><code>crud</code>: Contiene las funciones CRUD (Create, Read, Update, Delete) las cuales interactuan con la base de datos.</li> <li><code>db</code>: Contiene utilidades referidas a la conexion con la base de datos.</li> <li><code>models</code>: Contiene las clases constructoras de objetos utilizadas en el proyecto. Se diferencian dos tipos de clases, la primera clases de SQLAlchemy y clases de Pydantic. Las primeras son las encargadas de generar las tablas en la base de datos y gestionar la recuperacion e insercion de datos y las segundas son utilizadas como respuestas de los endpoints.</li> </ul> <p>La carpeta <code>ui</code> contiene todo lo referente a la UI, esta se compone de las subcarpetas:</p> <ul> <li><code>components</code>: Contiene componentes de react utilizados en las diferentes paginas o en diferentes componentes.</li> <li><code>pages</code>: Contiene la estructura de paginas y ruteo del servidor web. Es decir, el <code>index.ts</code> representa al <code>index.html</code> de <code>/</code>, mientras que el <code>/admin/index.ts</code> representa el <code>/admin/index.html</code>.</li> <li>Dentro de pages a su ves notamos una carpeta <code>api</code>, la cual funciona de intermediario entre la API de Fast Api y el servidor web de nextjs. Mediante esta, podemos evitar exponer directamente la API a los clientes.</li> <li><code>public</code>: Contiene los recursos publicos de la pagina web.</li> <li><code>utils</code>: Contiene definicion de interfaces (Parecidas a las clases pero solo denotan una estructura de datos) y configuraciones como la ruta de la API.</li> </ul>"},{"location":"2-body/#aclaracion-sobre-nextjs","title":"Aclaracion sobre NextJS","text":"<p>Next.js es un framework basado en React que facilita la renderizaci\u00f3n del c\u00f3digo en el servidor, entregando al cliente un conjunto de archivos HTML, CSS y JavaScript con la l\u00f3gica de acciones correspondiente. Cada p\u00e1gina React, definida como exportaci\u00f3n por defecto, debe ser pre-renderizada y enviada al cliente. Adem\u00e1s, el uso de <code>getServerSideProps</code> permite ejecutar c\u00f3digo antes de la renderizaci\u00f3n, posibilitando la limitaci\u00f3n de acceso a p\u00e1ginas bas\u00e1ndose en la presencia de cookies. Por otro lado, las rutas de API ubicadas en <code>ui/pages/api</code> son procesadas en el servidor.</p>"},{"location":"2-body/#ejemplos-y-pruebas","title":"Ejemplos y pruebas","text":"<p>Previo a la integracion con la UI, una vez todos los endpoints estaban desarollados, se procedio a probar cada uno de estos endpoints. Para esto se utilizo el Swagger que viene incorporado en Fast API que se encuentra en <code>http://localhost:8000/docs</code>:</p> <p>Para todos los endpoints, a la hora probarlos, deberemos seguir estos dos pazos, desplegar dicho endpoint y seleccionar el boton <code>Try it out</code>.</p> <p> </p> <p>En caso de querer crear un usuario:</p> <p> </p> <p>Para iniciar sesion con dicho usuario y mantener las credenciales guardadas para el resto de endpoints</p> <p> </p> <p>Para crear un producto:</p> <p></p> <p>Para obtener todos los productos debemos usar solo el boton <code>Try it out</code> sobre el endpoint <code>/products/get/all</code>.</p> <p>Una vez comprobada la funcionalidad de dichos endpoints, se procedio a desarollar y probar la UI:</p> <p></p> <p>Si seleccionamos administrar, al no estar logeados, nos redireccionara a la pagina de login:</p> <p></p> <p>Una vez logeados podemos ir a la pagina admin donde veremos nuestros productos, editarlos y borrarlos, ademas de agregarlos.</p> <p></p> <p>Para agregar un producto:</p> <p> </p> <p>Para editar, la interfaz es la misma, solo que se accede del boton de editar.</p> <p>Por ultimo para borrar, precionamos el icono de la papelera y nos saldra una confirmacion:</p> <p></p>"},{"location":"2-body/#como-levantar-un-cluster-y-desplegar-nuestra-aplicacion","title":"C\u00f3mo levantar un Cl\u00faster y desplegar nuestra aplicaci\u00f3n","text":""},{"location":"2-body/#vagrant","title":"Vagrant","text":"<p>Vagrant es una herramienta que pod\u00e9s usar para crear y gestionar entornos de desarrollo virtualizados de manera f\u00e1cil y reproducible. Su uso t\u00edpico es facilitar la creaci\u00f3n de m\u00e1quinas virtuales con configuraciones espec\u00edficas para el desarrollo de proyectos.</p> <p>Para comenzar un proyecto de Vagrant en el directorio /vagrant, el usuario puede seguir estos pasos:</p>"},{"location":"2-body/#instalacion-de-vagrant","title":"Instalaci\u00f3n de Vagrant","text":"<p>Antes que nada, necesit\u00e1s instalar Vagrant en tu m\u00e1quina. Esto se puede hacer descargando el instalador desde el sitio oficial y siguiendo las instrucciones</p>"},{"location":"2-body/#instalar-el-provider-de-virtualbox","title":"Instalar el provider de VirtualBox","text":"<p>Descargar de la  p\u00e1gina oficial.</p> <p>\u00a1Importante! Para poder configurar cierta red privada deberemos crear o modificar el archivo <code>/etc/vbox/networks.conf</code> a\u00f1adiendo la red de la siguiente manera:</p> <pre><code>sudo su\necho \"* 0.0.0.0/0\" &gt; /etc/vbox/networks.conf\n</code></pre>"},{"location":"2-body/#crear-las-claves-publicas-y-privadas-para-las-conexiones-ssh","title":"Crear las claves p\u00fablicas y privadas para las conexiones SSH","text":"<p>Creamos nuestra propia clave p\u00fablica y privada con <code>ssh-keygen</code>, procuramos no poner passphrase para que no se la solicite a las VMs a la hora de iniciarlas.</p> <pre><code># ~/.ssh/\n&gt; ssh-keygen -t rsa -b 4096\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/home/aagustin/.ssh/id_rsa): vagrant_key\nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in vagrant_key\nYour public key has been saved in vagrant_key.pub\nThe key fingerprint is:\nSHA256:K4v2o7EKOLfjCMLk7zVD4v234234c06peueU aagustin@hp-agustin\nThe key's randomart image is:\n+---[RSA 4096]----+\n|                 |\n|                 |\n|                 |\n|                 |\n| . . . .S     .  |\n|= . 3 o ..   o.. |\n|*o.+.*.... +.++. |\n|o=o.B4==  . *++  |\n|..=*+*=++ .+o. E |\n+----[SHA256]-----+\n</code></pre>"},{"location":"2-body/#instalacion-de-ansible","title":"Instalaci\u00f3n de Ansible","text":"<p>Ejecutamos los siguientes comandos en nuestra m\u00e1quina host:</p> <pre><code>sudo apt update\nsudo apt install software-properties-common\nsudo apt-add-repository ppa:ansible/ansible\nsudo apt update\nsudo apt install ansible\n</code></pre>"},{"location":"2-body/#personalizar-nuestros-archivos-de-configuracion-y-aprovisionar","title":"Personalizar nuestros archivos de configuraci\u00f3n y aprovisionar","text":""},{"location":"2-body/#configuraciones-de-perfil","title":"Configuraciones de perfil","text":"<p>Ingresamos al archivo <code>ansible/group_vars/all.yml</code> y elegimos la cantidad de nodos que deseemos, tambi\u00e9n la versi\u00f3n de Kubernetes. Adem\u00e1s seleccionamos los recursos.</p> <p>En nuestro caso se dej\u00f3 de la siguiente manera:</p> <pre><code>---\nsettings:\n  env: 'test_api'\n  users:\n    test_api:\n      prod_test: false\n\n      environment: \"\"\n\n      user_dir_path: /home/aagustin\n      node_home_dir: /home/vagrant\n\n      shared_folders:\n        - host_path: ./shared_folder\n          vm_path: /home/vagrant \n\n      cluster_name: Kubernetes Cluster\n\n      ssh:\n        user: \"vagrant\"\n        password: \"vagrant\"\n        private_key_path: /home/aagustin/.ssh/vagrant_key # Crearse una para que funcione\n        public_key_path: /home/aagustin/.ssh/vagrant_key.pub # Crearse una para que funcione\n\n      nodes:\n        control:\n          cpu: 2\n          memory: 4096 \n        workers:\n          count: 2 \n          cpu: 2 \n          memory: 4096 \n\n      network:\n        control_ip: 192.168.100.171\n        dns_servers:\n          - 8.8.8.8\n          - 1.1.1.1\n        pod_cidr: 172.16.1.0/16\n        service_cidr: 172.17.1.0/18\n\n\n      software:\n        box: bento/ubuntu-22.04\n        calico: 3.25.0\n        kubernetes: 1.26.1-00\n        os: xUbuntu_22.04\n\n        flannel: 0.23.0\n        contained: v1.5\n</code></pre>"},{"location":"2-body/#levantar-maquinas-virtuales-de-vagrant","title":"Levantar m\u00e1quinas virtuales de Vagrant","text":"<p>Levantarlas:</p> <pre><code># en &lt;project-dir&gt;/k8s/\nvagrant up\n</code></pre> <p>Si deseamos eliminarlas:</p> <pre><code># en &lt;project-dir&gt;/k8s/\nvagrant destroy\n</code></pre>"},{"location":"2-body/#aprovisionamos-con-ansible","title":"Aprovisionamos con Ansible","text":"<p>Desde la m\u00e1quina host, posicionados en <code>&lt;project-dir&gt;/k8s/</code>, ejecutaremos los siguientes comandos:</p> <pre><code>ansible -i ansible/inventory_local.yml -m ping all\n</code></pre> <p>Y nos aseguraremos de tener respuesta de todos los nodos creados.</p> <p>Y luego aprovisionamos con:</p> <pre><code>ansible-playbook -vvv ansible/site.yml -i ansible/inventory_local.yml\n</code></pre>"},{"location":"2-body/#acceso-a-los-nodos-mediante-ssh","title":"Acceso a los nodos mediante SSH","text":"<p>Para acceder al nodo master:</p> <pre><code>ssh -i ~/.ssh/vagrant_key vagrant@192.168.100.171\n</code></pre> <p>Si queremos entrar como <code>root</code> simplemente cambiamos el usuario a root.</p>"},{"location":"2-body/#minikube","title":"Minikube","text":"<p>Se detectaron problemas de DNS en el Cluster de Vagrant, estos son f\u00e1cilmente verificables generando un pod de test dns-utils y aplicando el siguiente comando:</p> <pre><code>kubectl exec -i -t dnsutils -- nslookup &lt;nombre-servicio&gt;.svc.default.cluster.local\n</code></pre> <p>Donde deber\u00edamos obtener la IP del servicio o del pod al que estamos queriendo llegar con ese dominio. En el caso del Cluster de Vagrant no se obten\u00edan las direcciones IP correspondientes, esto nos asegura que el <code>core-dns</code> no est\u00e1 funcionando como corresponde lo que indica una mala intalaci\u00f3n de <code>kubelet</code>.</p> <p>Resulta, que por experiencias previas sab\u00edamos que esto pod\u00eda ser as\u00ed debido a que la configuraci\u00f3n propuesta de Vagrant no permite los reinicios debido a que se corrompen las carpetas compartidas y al no poder reiniciar no se aplican como corresponde las configuraciones pertinentes al aprovisionamiento de Kubernetes.</p> <p>Dicho esto, y entendiendo adem\u00e1s que se complican las pruebas en local, se tom\u00f3 la decisi\u00f3n de conservar la versi\u00f3n utilizada de Kubernetes (1.26.1) y hacer uso de Minikube, una herramienta opensource que mediante la creaci\u00f3n de una m\u00e1quina virtual nos permite disponer de un entorno sencillo de Kubernetes con la mayor parte de sus funcionalidades.</p> <p>Para levantar el cluster necesario, ya teniendo Minikube instalado, aplicamos el siguiente comando:</p> <pre><code>minikube start --kubernetes-version='1.26.1' --memory='4096' --cpus='2' --disk-size='10GB' --vm=true --nodes=2 -p \"test-1.26-2nodes\"\nminikube addons enable metrics-server\n</code></pre> <p>Podemos borrar nuestro perfil creado haciendo:</p> <pre><code>minikube delete -p test-1.26-2nodes\n</code></pre> <p>Podemos levantar el Dashboard para una mejor visualizaci\u00f3n de lo que ocurre con:</p> <pre><code>minikube dashboard -p test-1.26-2nodes\n</code></pre>"},{"location":"2-body/#levantar-base-de-datos-mysql","title":"Levantar base de datos MySQL","text":""},{"location":"2-body/#por-que-mysql-y-no-mongodb-u-alguna-otra","title":"\u00bfPor qu\u00e9 MySQL y no MongoDB u alguna otra?","text":"<p>Se hizo la b\u00fasqueda de informaci\u00f3n pertinente para poder hacer una selecci\u00f3n adecuada para los requerimientos y en la misma se encontr\u00f3 que entre las bases de datos m\u00e1s utilizadas dentro de los entornos de Kubernetes son MySQL y PostgressSQL y que adem\u00e1s, el uso de una base de datos en un entorno de Kuebernetes no es una decisi\u00f3n que debamos tomar a la ligera, debido a que resulta muy complicado el mantenimiento y la misma configuraci\u00f3n.</p> <p>Entendiendo lo anterior, se opt\u00f3 por MySQL como base de datos para el proyecto y la misma se desplegar\u00e1 sobre Kubernetes en una configuraci\u00f3n denominada \"Statefulset\", que permite desplegar nombres de pods y vol\u00famenes persistentes.</p>"},{"location":"2-body/#que-arquitectura-elegimos-y-por-que","title":"\u00bfQu\u00e9 arquitectura elegimos y por qu\u00e9?","text":"<p>Se probaron 3 diferentes formas para levantar la base de datos en las cuales nos hemos topado con distitos inconvenientes por lo cuales hemos llegado a una decisi\u00f3n final.</p> <p>Dentro de las pruebas se lograron diferenciar conceptos importantes:</p>"},{"location":"2-body/#headless-services-vs-clusterip-services-vs-nodeport-services","title":"Headless Services vs. ClusterIP Services vs. NodePort Services","text":"<p>Los Headless Services no asignan una direcci\u00f3n IP virtual estable, en lugar de eso, devuelven directamente las IP de los pods seleccionados, se usa cuando necesitas acceder a cada instancia individualmente, por ejemplo, en bases de datos distribuidas. Estos realizan \"loadbalancing\" a la hora de tener que distribuir el tr\u00e1fico (no le pegan siempre al mmismo pod).</p> <p>Los ClusterIP Services asignan una IP virtual estable que representa el servicio y dirige el tr\u00e1fico a los pods seleccionados. Son ideales para servicios internos en el cl\u00faster que solo necesitan ser accedidos internamente. Estos realizan balanceo de carga entre los pods seleccionados.</p> <p>Los NodePort Services exponen el servicio en un puerto en cada nodo del cl\u00faster, permitiendo el acceso externo. Son \u00fatiles cuando necesitas acceder al servicio desde fuera del cl\u00faster, pero no es ideal para producci\u00f3n debido a posibles problemas de seguridad. Este tipo de servicio proporciona balanceo de carga entre los nodos, pero no entre los pods directamente.</p>"},{"location":"2-body/#statefulset","title":"Statefulset","text":"<p>Es un controlador que mantiene un conjunto de pods con identidades \u00fanicas y persistentes. Se utiliza para aplicaciones que requieren identidades persistentes, como bases de datos, donde cada pod tiene un estado y un nombre \u00fanico. Garantiza que los pods se creen y se escalen de manera ordenada, y proporciona almacenamiento persistente para cada pod.</p> <p>A diferencia de Deployments, que son m\u00e1s adecuados para aplicaciones sin estado, un StatefulSet es ideal cuando se necesita mantener un estado espec\u00edfico y \u00fanico para cada instancia, como en el caso de bases de datos.</p> <p>Supongamos que tenemos un StatefulSet para una base de datos MySQL y decidimos llamar al  StatefulSet \"mysql-db\". La nomenclatura para los nombres de los pods y persistent volumes generados por el StatefulSet ser\u00eda algo como:</p> <ul> <li>Pods generados por el StatefulSet:</li> </ul> <pre><code>mysql-db-0\nmysql-db-1\nmysql-db-2\n</code></pre> <ul> <li>Persistent Volumes generados por el StatefulSet:</li> </ul> <pre><code>mysql-db-pv-0\nmysql-db-pv-1\nmysql-db-pv-2\n</code></pre> <p>Cada pod y cada volumen persistente tendr\u00eda un nombre \u00fanico basado en el nombre del StatefulSet y un \u00edndice que refleja su posici\u00f3n en la secuencia.</p> <p>Ahora, si tuvieramos un Deployment com\u00fan para una aplicaci\u00f3n web llamado \"web-app\", los nombres de los pods generados ser\u00edan m\u00e1s gen\u00e9ricos y probablemente se basar\u00edan en un identificador aleatorio o alg\u00fan nombre de base, como:</p> <ul> <li>Pods generados por el Deployment:</li> </ul> <pre><code>web-app-74d8b8b5f9-abcde\nweb-app-74d8b8b5f9-12345\nweb-app-74d8b8b5f9-xyzab\n</code></pre> <ul> <li>Persistent Volumes generados por el Deployment: No habr\u00eda persistent volumes espec\u00edficos asociados directamente con los pods generados por el Deployment, a menos que configures almacenamiento persistente externamente.</li> </ul> <p>En resumen, la diferencia radica en la predictibilidad y consistencia de los nombres. Los StatefulSets generan nombres que reflejan la posici\u00f3n y el prop\u00f3sito espec\u00edfico del pod en la secuencia, mientras que los Deployments comunes pueden generar nombres m\u00e1s aleatorios o gen\u00e9ricos.</p>"},{"location":"2-body/#replicar-la-base-de-datos","title":"Replicar la base de datos","text":"<p>Supongamos que gracias a los servicios configurados y nuestra API logramos escribir sobre la base de datos del Statefulset de MySQL, que para este ejemplo consta de 3 pods y por consiguiente 3 PV's.</p> <p>Si hacemos intentos reiterados para escribir sobre la base de datos resultar\u00eda que, gracias al balanceo de cargas realizado por el servicio ClusterIP o Headless, escribir\u00edamos algunos datos en una de las r\u00e9plicas, otros en la siguiente y as\u00ed sucesivamente, resultando que, cuando quisieramos leer, no obtendr\u00edamos todos los datos de una vez ya que cada r\u00e9plica es una base de datos independientes y requerimos de una l\u00f3gica extra para hacer la replicaci\u00f3n de la informaci\u00f3n y as\u00ed esta est\u00e9 disponible en todas las replicas.</p> <p>En el contexto de las DB, podemos configurar un conjunto de r\u00e9plicas utilizando un controlador StatefulSet y configurar la replicaci\u00f3n de cada tipo de DB dentro de los pods.</p>"},{"location":"2-body/#eleccion-tomada","title":"Elecci\u00f3n tomada","text":"<p>Entendiendo lo anterior, creemos que un Headless service y una configuraci\u00f3n Statefulset es la major elecci\u00f3n para desplegar nuestra base de datos.</p> <p>A la hora de la configuraci\u00f3n sobre Minikube se encontr\u00f3 que la configuraci\u00f3n de replicaci\u00f3n de la DB que nos ofrece de ejemplo la documentaci\u00f3n de Kubernetes no funciona como corresponde.</p> <p>Debido a lo nombrado anteriormente es que se opt\u00f3 por una base de datos en una configuraci\u00f3n Statefulset pero que contenga una \u00fanica r\u00e9plica as\u00ed nos olvidamos del problema de la no-replicaci\u00f3n.</p> <p></p>"},{"location":"2-body/#manifiestos-de-kubernetes-de-la-db","title":"Manifiestos de Kubernetes de la DB","text":"<p>Aqu\u00ed se brinda el manifiesto utilizado:</p> <pre><code>---\napiVersion: v1\nkind: Service\nmetadata:\n  name: mysql-headless\nspec:\n  clusterIP: None\n  selector:\n    app: db\n  ports:\n    - name: tcp\n      protocol: TCP\n      port: 3306\n---\n# $ echo -n \"root\" | base64\n# cm9vdA==\napiVersion: v1\nkind: Secret\nmetadata: \n    name: mysecret\ntype: Opaque\ndata:\n   ROOT_PASSWORD: cm9vdA==\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: mysql-initdb-config\ndata:\n  init.sql: |\n    CREATE DATABASE IF NOT EXISTS api;\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: mysql\nspec:\n  replicas: 1\n  serviceName: mysql-headless\n  selector:\n    matchLabels:\n      app: db\n  template:\n    metadata:\n      labels:\n        app: db\n    spec:\n      terminationGracePeriodSeconds: 10\n      containers:\n        - name: mysql\n          image: mysql:5.7\n          ports:\n            - containerPort: 3306\n          env:\n            - name: MYSQL_ROOT_PASSWORD\n              valueFrom: \n               secretKeyRef: \n                key: ROOT_PASSWORD\n                name: mysecret\n          volumeMounts:\n            - name: mysql-initdb\n              mountPath: /docker-entrypoint-initdb.d\n            - name: data\n              mountPath: /var/lib/mysql\n      volumes:\n      - name: mysql-initdb\n        configMap:\n          name: mysql-initdb-config\n  volumeClaimTemplates:\n    - metadata:\n        name: data\n      spec:\n        accessModes: [ \"ReadWriteOnce\" ]\n        resources:\n          requests:\n            storage: 1Gi\n</code></pre> <p>Desplegar:</p> <pre><code>kubectl apply -f &lt;nombre-manifiesto-db&gt;.yaml\n</code></pre> <p>Eliminar:</p> <pre><code>kubectl delete -f &lt;nombre-manifiesto-db&gt;.yaml\n</code></pre> <p>La DB quedar\u00e1 accesible entonces v\u00eda el siguiente dominio:</p> <pre><code>mysql+pymysql://root:root@mysql-0.mysql-headless.default.svc.cluster.local:3306/api\n</code></pre>"},{"location":"2-body/#backend-desplegar-la-api","title":"Backend - Desplegar la API","text":"<p>La API debe ser accesible por fuera con el uso de un servicio tipo NodePort y a su vez debe poder acceder a la DB mediante el uso de DNS, pegandole al pod correspondiente (o al servicio, da igual porque tenemos un \u00fanico pod) de la DB.</p> <p>Para ello se cre\u00f3 el siguiente manifiesto:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: api \nspec:\n  type: NodePort\n  ports:\n    - port: 8000\n      targetPort: 8000\n      nodePort: 31000\n  selector:\n    app: api\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api\n  labels:\n    app: api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: api\n  template:\n    metadata:\n      labels:\n        app: api\n    spec:\n      containers:\n        - name: api-backend-fastapi\n          image: aagustinconti/fast-api-products:latest #DockerHub repo\n          ports:\n            - containerPort: 8000\n          imagePullPolicy: Always\n          env:\n          - name: MYSQL_HOST\n            value: mysql-0.mysql-headless.default.svc.cluster.local\n          - name: MYSQL_USER\n            value: root\n          - name: MYSQL_PASSWORD\n            value: root\n          - name: MYSQL_DATABASE\n            value: api\n          - name: DATABASE_URI\n            value: 'mysql+pymysql://root:root@mysql-0.mysql-headless.default.svc.cluster.local:3306/todo'\n</code></pre> <p>Desplegar:</p> <pre><code>kubectl apply -f &lt;nombre-manifiesto-api&gt;.yaml\n</code></pre> <p>Eliminar:</p> <pre><code>kubectl delete -f &lt;nombre-manifiesto-api&gt;.yaml\n</code></pre> <p>Como dato a tener en cuenta, la API estar\u00e1 disponible en el puerto 31000 de la IP del nodo worker. Internamente el container tendr\u00e1 expuesto el puerto 8000, el cual estar\u00e1 apuntado por el servicio tipo NodePort para poder exponerlo al 31000, justamente.</p> <p>Otro dato importante es que se tuvo que dockerizar la API y subir la imagen al DockerHub para que Kubernetes la pueda descargar, como se ve, esta est\u00e1 disponible en <code>aagustinconti/fast-api-products:latest</code>.</p> <p>La gr\u00e1fica quedar\u00eda de la siguiente manera:</p> <p></p>"},{"location":"2-body/#frontend-desplegar-la-ui","title":"Frontend - Desplegar la UI","text":"<p>La UI debe poder comunicarse con la API y y a su vez debe ser accesible desde el puerto 80 de la IP del nodo as\u00ed los usuarios pueden acceder a la misma. Para lo anterior se cre\u00f3 otro servicio tipo NodePort y a su vez se le pasaron los datos importantes para que se pueda conectar a la API, como el host: <code>mysql-0.mysql-headless.default.svc.cluster.local</code>, la clave, el usuario y la DB.</p> <p>El manifiesto utilizado fue el siguiente:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: ui \nspec:\n  type: NodePort\n  ports:\n    - port: 80\n      targetPort: 80\n      nodePort: 30001\n  selector:\n    app: ui\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ui\n  labels:\n    app: ui\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ui\n  template:\n    metadata:\n      labels:\n        app: ui\n    spec:\n      containers:\n        - name: api-frontend-node\n          image: aagustinconti/ui-node-products:latest # DockerHub repo\n          ports:\n            - containerPort: 80\n          imagePullPolicy: Always\n          env:\n          # &lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local:&lt;service-port&gt;\n          - name: API_URL\n            value: 'http://api:8000'\n          - name: PORT\n            value: '80'\n</code></pre> <p>Desplegar:</p> <pre><code>kubectl apply -f &lt;nombre-manifiesto-ui&gt;.yaml\n</code></pre> <p>Eliminar:</p> <pre><code>kubectl delete -f &lt;nombre-manifiesto-ui&gt;.yaml\n</code></pre> <p>Nuevamente se utiliz\u00f3 Docker para crear la im\u00e1gen y subirla al DockerHub para que sea accesible por Kubernetes a trav\u00e9s de <code>aagustinconti/ui-node-products:latest</code>.</p> <p>Por otro lado debemos observar algo clave, entre los valores de las variables de entorno que le suministramos, encontramos que encuentra perfectamente a la api mediante el servicio \"api\" en el puerto 8000 (utilizando la resoluci\u00f3n de DNS).</p> <p>El diagrama queda como sigue:</p> <p></p>"},{"location":"2-body/#como-paso-la-dockerfile-a-dockerhub","title":"\u00bfComo paso la Dockerfile a DockerHub?","text":"<ol> <li> <p>Crearse una cuenta en DockerHub</p> </li> <li> <p>Crear un repositorio p\u00fablico</p> </li> </ol> <p></p> <ol> <li>Buildear la im\u00e1gen en local</li> </ol> <pre><code>docker build -f ./app/Dockerfile .\n</code></pre> <ol> <li>Checkeamos la creaci\u00f3n de la im\u00e1gen</li> </ol> <pre><code>docker images\n</code></pre> <ol> <li>Aplicar el siguiente comando</li> </ol> <pre><code>docker tag &lt;nombre-imagen&gt; &lt;dockerhub-user&gt;/&lt;nombre-imagen&gt;\ndocker push &lt;dockerhub-user&gt;/&lt;nombre-repositorio-dockerhub&gt;\n</code></pre>"},{"location":"2-body/#monitoreo-de-los-recursos-utilizados","title":"Monitoreo de los recursos utilizados","text":""},{"location":"2-body/#grafana-y-prometheus","title":"Grafana y Prometheus","text":""},{"location":"2-body/#instalacion","title":"Instalaci\u00f3n","text":"<ol> <li>Descargar repositorio del operador:</li> </ol> <pre><code>git clone https://github.com/prometheus-operator/kube-prometheus.git\ncd kube-prometheus\n</code></pre> <ol> <li>Instalar el operador:</li> </ol> <pre><code>kubectl apply --server-side -f manifests/setup\n</code></pre> <ol> <li>Instalar todos los elementos:</li> </ol> <pre><code>kubectl apply -f manifests \n</code></pre> <ol> <li>Checkeamos que se hayan levantado todos los servicios, replicasets y pods:</li> </ol> <pre><code>kubectl get all -n monitoring\n</code></pre> <ol> <li>Editamos los servicios para poder exponerlos, de ClusterIP a NodePort a todos:</li> </ol> <pre><code>kubectl edit svc grafana -n monitoring\n</code></pre> <pre><code>kubectl edit svc prometheus-k8s -n monitoring\n</code></pre> <pre><code>kubectl edit svc alertmanager-main -n monitoring\n</code></pre> <ol> <li>Listamos los nodos, buscamos la IP del worker:</li> </ol> <pre><code>kubectl get nodes -o wide\n</code></pre> <ol> <li>Listamos todos los servicios y buscamos el puerto al que se ha expuesto:</li> </ol> <pre><code>kubectl get svc -A\n</code></pre> <p>Checkeamos los puertos <code>grafana</code>, <code>prometheus-k8s</code> y <code>alertmanager-main</code> que tengan \"NodePort\".</p> <ol> <li>Ingresamos a <code>&lt;ip-nodo-worker&gt;:&lt;puerto-svc&gt;</code></li> </ol>"},{"location":"2-body/#ejemplo-grafana","title":"Ejemplo grafana","text":"<p>user: <code>admin</code>, psw: <code>admin</code></p> <p>A\u00f1adimos de datasource a Prometheus y configuramos un dashboard con algunos datos, por ejemplo, memoria disponible:</p> <p></p> <p></p>"},{"location":"2-body/#levantar-la-base-de-datos-mysql-en-grafana","title":"Levantar la base de datos MySQL en Grafana","text":"<p>Vamos a <code>Data Sources</code>, luego <code>Add Data Sources</code>, luego elegimos MySQL y colocamos:</p> <ul> <li>Host URL: <code>mysql-0.mysql-headless.default.svc.cluster.local:3306</code></li> <li>Database name: <code>&lt;nombre-db&gt;</code></li> <li>Username: <code>root</code></li> <li>Password: <code>root</code></li> </ul> <p>Hacemos click en <code>Save and Test</code>.</p> <p>Luego podremos crear un dashboard donde traigamos como tabla, por ejemplo, los datos de la tabla:</p> <p></p>"},{"location":"2-body/#k6","title":"k6","text":""},{"location":"2-body/#que-es-k6","title":"\u00bfQu\u00e9 es k6?","text":"<p>k6 es una herramienta de c\u00f3digo abierto destinada a realizar pruebas de carga y rendimiento en aplicaciones y servicios web. Utilizando JavaScript/ES6 para escribir scripts de prueba, k6 destaca por su sencilla sintaxis y soporte para protocolos como HTTP/1.1, HTTP/2 y WebSockets. Dise\u00f1ado para ejecutarse en la nube y ser f\u00e1cilmente integrado en flujos de trabajo de CI/CD, k6 proporciona informes detallados y m\u00e9tricas para evaluar el rendimiento de las aplicaciones bajo diversas condiciones de carga. Su flexibilidad y extensibilidad lo convierten en una herramienta valiosa para evaluar y mejorar la escalabilidad de sistemas web.</p> <p>Entonces, k6 simplifica la realizaci\u00f3n de pruebas de rendimiento al ofrecer una soluci\u00f3n basada en JavaScript con caracter\u00edsticas como integraci\u00f3n en la nube, generaci\u00f3n de informes detallados y soporte para varios protocolos, proporcionando a los equipos de desarrollo la capacidad de evaluar y optimizar el rendimiento de sus aplicaciones de manera efectiva.</p> <p>Gracias a ella pudimos plantear pruebas de stress locales hacia diferentes host y endpoints de nuestra api para poder verificar el cumplimiento de los requerimientos acordados con el cliente.</p>"},{"location":"2-body/#k6-junto-con-prometheus-y-grafana","title":"K6 junto con Prometheus y Grafana","text":"<p>La visualizaci\u00f3n de datos a trav\u00e9s de Grafana en conjunto con Prometheus ofrece una visi\u00f3n integral y en tiempo real del rendimiento del cluster que hospeda la aplicaci\u00f3n. Al integrar estad\u00edsticas proporcionadas por k6 con los datos de consumo de recursos obtenidos mediante Prometheus, los equipos de desarrollo y operaciones pueden identificar patrones y correlaciones significativas. Esto permite una comprensi\u00f3n profunda de c\u00f3mo las pruebas de carga impactan los recursos del cluster y c\u00f3mo estos afectan directamente al rendimiento de la aplicaci\u00f3n en producci\u00f3n. Grafana, con sus capacidades de visualizaci\u00f3n altamente personalizables, proporciona paneles intuitivos y gr\u00e1ficos din\u00e1micos que facilitan la identificaci\u00f3n de tendencias, cuellos de botella y \u00e1reas de mejora, permitiendo una toma de decisiones informada para optimizar la escalabilidad y la eficiencia del sistema.</p> <p>La combinaci\u00f3n de k6, Prometheus y Grafana proporciona una sinergia poderosa al permitir que los equipos monitoreen y analicen simult\u00e1neamente el rendimiento de las pruebas de carga y el comportamiento del cluster en producci\u00f3n. Esta integraci\u00f3n facilita la identificaci\u00f3n proactiva de posibles problemas y la optimizaci\u00f3n continua del rendimiento, respaldando la toma de decisiones basada en datos con una representaci\u00f3n visual clara y detallada de la salud y eficiencia del sistema en tiempo real.</p>"},{"location":"2-body/#instalacion-de-k6","title":"Instalaci\u00f3n de k6","text":"<p>En Debian/Ubuntu, seguimos los pasos de la p\u00e1gina de K6.</p> <p>Simplemente correremos en consola lo siguiente:</p> <pre><code>sudo gpg -k\nsudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69\necho \"deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main\" | sudo tee /etc/apt/sources.list.d/k6.list\nsudo apt-get update\nsudo apt-get install k6\n</code></pre>"},{"location":"2-body/#correr-el-test-de-carga","title":"Correr el test de carga","text":"<p>Para correr cualquier test lo \u00fanico que debemos hacer es poner en consola lo siguiente:</p> <pre><code># on k6 dir\nk6 run test-api/&lt;nombre-del-test&gt;.js\n</code></pre>"},{"location":"2-body/#pruebas-realizadas","title":"Pruebas realizadas","text":"<p>Las pruebas se centraron en cumplir con los requisitos de resistencia del cliente, priorizando la capacidad de la interfaz de usuario para soportar m\u00e1s de 5000 usuarios simult\u00e1neos en su p\u00e1gina principal. Adem\u00e1s, se llevaron a cabo pruebas adicionales, como la creaci\u00f3n masiva de usuarios y productos para evaluar la robustez de la API y la base de datos. Otra prueba se centr\u00f3 en medir el consumo de red al recuperar datos en formato base64 de im\u00e1genes completas desde la base de datos. Por \u00faltimo, se evalu\u00f3 el rendimiento del procesamiento de la API, incluyendo pruebas de carga en el proceso de inicio de sesi\u00f3n que involucra tokens y contrase\u00f1as encriptadas con BCrypt. En todos los escenarios, se monitorearon detenidamente la CPU, la RAM, la lectura/escritura del disco y el consumo de red para obtener una visi\u00f3n completa del rendimiento del sistema.</p>"},{"location":"2-body/#test-1-ui","title":"Test 1: UI","text":"<p>Archivo de configuraci\u00f3n de K6 utilizado:</p> <pre><code>import http from 'k6/http';\nimport { sleep } from 'k6';\n\nexport const options = {\n  stages: [\n    { duration: '15s', target: 1000 },\n    { duration: '30s', target: 2500 },\n    { duration: '1m', target: 5000 },\n  ],\n};\n\nexport default function () {\n  http.get('http://192.168.39.203:30001/');\n  sleep(1);\n}\n</code></pre> <p>Resultado de consola de k6:</p> <pre><code>     data_received..................: 141 MB 1.1 MB/s\n     data_sent......................: 1.3 MB 10 kB/s\n     http_req_blocked...............: avg=74.96ms  min=951ns  med=5.29\u00b5s  max=7.3s   p(90)=529.72\u00b5s p(95)=5.64ms  \n     http_req_connecting............: avg=42.82ms  min=0s     med=0s      max=7.3s   p(90)=357.86\u00b5s p(95)=447.3\u00b5s \n     http_req_duration..............: avg=25.35s   min=8.63ms med=23.68s  max=1m0s   p(90)=46.43s   p(95)=49.46s  \n       { expected_response:true }...: avg=24.8s    min=8.63ms med=23.67s  max=59.98s p(90)=44.26s   p(95)=47.46s  \n     http_req_failed................: 1.57%  \u2713 227        \u2717 14208 \n     http_req_receiving.............: avg=84.93\u00b5s  min=0s     med=80.47\u00b5s max=4.41ms p(90)=113.12\u00b5s p(95)=127.36\u00b5s\n     http_req_sending...............: avg=430.38ms min=5.32\u00b5s med=21.77\u00b5s max=9.55s  p(90)=83.96\u00b5s  p(95)=4.17s   \n     http_req_tls_handshaking.......: avg=0s       min=0s     med=0s      max=0s     p(90)=0s       p(95)=0s      \n     http_req_waiting...............: avg=24.92s   min=8.44ms med=23.68s  max=1m0s   p(90)=41.57s   p(95)=49.46s  \n     http_reqs......................: 14435  110.617989/s\n     iteration_duration.............: avg=26.4s    min=1s     med=24.69s  max=1m1s   p(90)=47.43s   p(95)=50.46s  \n     iterations.....................: 14435  110.617989/s\n     vus............................: 744    min=42       max=4984\n     vus_max........................: 5000   min=5000     max=5000\n\n\nrunning (2m10.5s), 0000/5000 VUs, 14435 complete and 0 interrupted iterations\ndefault \u2713 [======================================] 0000/5000 VUs  1m45s\n</code></pre> <p>Resultado de Grafana:</p> <p> </p>"},{"location":"2-body/#test-2-user-login","title":"Test 2: User login","text":"<p>Archivo de configuraci\u00f3n de K6 utilizado:</p> <pre><code>import http from 'k6/http';\nimport { check, sleep } from 'k6';\n\nexport const options = {\n  stages: [\n    { duration: '15s', target: 1000 },\n    { duration: '30s', target: 2500 },\n    { duration: '1m', target: 5000 },\n  ],\n};\n\nexport default function () {\n  // Datos del usuario para el login\n  const username = 'aagustin@gmail.com';\n  const password = '12345678';\n\n  // Realizar la solicitud POST para el login del usuario\n  const res = http.post('http://192.168.39.203:31000/auth/login', {\n    grant_type: '',\n    username,\n    password,\n    scope: '',\n    client_id: '',\n    client_secret: '',\n  }, {\n    headers: {\n      'Content-Type': 'application/x-www-form-urlencoded',\n      'Accept': 'application/json',\n    },\n  });\n\n  // Verificar si la respuesta es exitosa (c\u00f3digo 2xx)\n  check(res, {\n    'status was 2xx': (r) =&gt; r.status &gt;= 200 &amp;&amp; r.status &lt; 300,\n  });\n\n  // Introducir una pausa de 1 segundo entre las solicitudes\n  sleep(1);\n}\n</code></pre> <p>Resultado de consola de k6:</p> <pre><code>     \u2717 status was 2xx\n      \u21b3  3% \u2014 \u2713 407 / \u2717 12074\n\n     checks.........................: 3.26%  \u2713 407       \u2717 12074 \n     data_received..................: 126 kB 993 B/s\n     data_sent......................: 3.5 MB 28 kB/s\n     http_req_blocked...............: avg=513.73ms min=2.45\u00b5s   med=1.11ms   max=3.13s    p(90)=3.02s    p(95)=3.03s \n     http_req_connecting............: avg=513.25ms min=0s       med=949.58\u00b5s max=3.05s    p(90)=3.02s    p(95)=3.03s \n     http_req_duration..............: avg=29.51s   min=452.04ms med=31.15s   max=50.44s   p(90)=37.05s   p(95)=41.74s\n       { expected_response:true }...: avg=9.24s    min=452.04ms med=7.96s    max=32.5s    p(90)=19.42s   p(95)=27.41s\n     http_req_failed................: 96.73% \u2713 12074     \u2717 407   \n     http_req_receiving.............: avg=4.57\u00b5s   min=0s       med=0s       max=8.86ms   p(90)=0s       p(95)=0s    \n     http_req_sending...............: avg=718.89\u00b5s min=11.89\u00b5s  med=66.83\u00b5s  max=101.88ms p(90)=510.25\u00b5s p(95)=1.15ms\n     http_req_tls_handshaking.......: avg=0s       min=0s       med=0s       max=0s       p(90)=0s       p(95)=0s    \n     http_req_waiting...............: avg=29.51s   min=451.86ms med=31.15s   max=50.44s   p(90)=37.05s   p(95)=41.74s\n     http_reqs......................: 12481  98.263787/s\n     iteration_duration.............: avg=31.22s   min=1.46s    med=33.61s   max=51.91s   p(90)=38.37s   p(95)=43.05s\n     iterations.....................: 12481  98.263787/s\n     vus............................: 982    min=41      max=4995\n     vus_max........................: 5000   min=5000    max=5000\n\n\nrunning (2m07.0s), 0000/5000 VUs, 12481 complete and 0 interrupted iterations\ndefault \u2713 [======================================] 0000/5000 VUs  1m45s\n</code></pre> <p>Resultado de Grafana:</p> <p> </p>"},{"location":"2-body/#test-3-register-new-users","title":"Test 3: Register new users","text":"<p>Archivo de configuraci\u00f3n de K6 utilizado:</p> <pre><code>import http from 'k6/http';\nimport { check, sleep } from 'k6';\n\n// Funci\u00f3n para generar una cadena aleatoria de longitud dada\nfunction generateRandomString(length) {\n  const charset = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789';\n  let result = '';\n  for (let i = 0; i &lt; length; i++) {\n    const randomIndex = Math.floor(Math.random() * charset.length);\n    result += charset.charAt(randomIndex);\n  }\n  return result;\n}\n\nexport const options = {\n  stages: [\n    { duration: '15s', target: 1000 },\n    { duration: '30s', target: 2500 },\n    { duration: '1m', target: 5000 },\n  ],\n};\n\nexport default function () {\n  // Generar datos aleatorios para cada usuario\n  const email = `user${Math.floor(Math.random() * 100000)}@example.com`;\n  const password = generateRandomString(8);\n\n  // Crear el objeto de usuario\n  const user = {\n    email,\n    password,\n  };\n\n  // Realizar la solicitud POST para registrar un nuevo usuario\n  const res = http.post('http://192.168.39.203:31000/auth/register', JSON.stringify({ user }), {\n    headers: {\n      'Content-Type': 'application/json',\n      'Accept': 'application/json',\n    },\n  });\n\n  // Verificar si la respuesta es exitosa (c\u00f3digo 2xx)\n  check(res, {\n    'status was 2xx': (r) =&gt; r.status &gt;= 200 &amp;&amp; r.status &lt; 300,\n  });\n\n  // Introducir una pausa de 1 segundo entre las solicitudes\n  sleep(1);\n}\n</code></pre> <p>Resultado de consola de k6:</p> <pre><code> \u2717 status was 2xx\n      \u21b3  2% \u2014 \u2713 345 / \u2717 11276\n\n     checks.........................: 2.96%  \u2713 345       \u2717 11276 \n     data_received..................: 122 kB 952 B/s\n     data_sent......................: 2.8 MB 22 kB/s\n     http_req_blocked...............: avg=241.39ms min=2.51\u00b5s   med=610.72\u00b5s max=7.14s    p(90)=1.03s    p(95)=1.05s \n     http_req_connecting............: avg=241.29ms min=0s       med=532.82\u00b5s max=7.14s    p(90)=1.03s    p(95)=1.05s \n     http_req_duration..............: avg=31.44s   min=372.26ms med=31.69s   max=58.3s    p(90)=41.86s   p(95)=46.66s\n       { expected_response:true }...: avg=8.98s    min=372.26ms med=6.89s    max=37.73s   p(90)=20.51s   p(95)=25.54s\n     http_req_failed................: 97.03% \u2713 11276     \u2717 345   \n     http_req_receiving.............: avg=2.46\u00b5s   min=0s       med=0s       max=532.61\u00b5s p(90)=0s       p(95)=0s    \n     http_req_sending...............: avg=229.78\u00b5s min=10.67\u00b5s  med=59.28\u00b5s  max=11.64ms  p(90)=408.53\u00b5s p(95)=1.26ms\n     http_req_tls_handshaking.......: avg=0s       min=0s       med=0s       max=0s       p(90)=0s       p(95)=0s    \n     http_req_waiting...............: avg=31.44s   min=372.09ms med=31.69s   max=58.3s    p(90)=41.86s   p(95)=46.66s\n     http_reqs......................: 11621  91.116311/s\n     iteration_duration.............: avg=32.78s   min=1.37s    med=32.84s   max=59.53s   p(90)=43.03s   p(95)=47.82s\n     iterations.....................: 11621  91.116311/s\n     vus............................: 766    min=41      max=4994\n     vus_max........................: 5000   min=5000    max=5000\n\n\nrunning (2m07.5s), 0000/5000 VUs, 11621 complete and 0 interrupted iterations\ndefault \u2713 [======================================] 0000/5000 VUs  1m45s\n</code></pre> <p>Resultado de Grafana:</p> <p> </p>"},{"location":"2-body/#test-4-register-new-products","title":"Test 4: Register new products","text":"<p>Archivo de configuraci\u00f3n de K6 utilizado:</p> <pre><code>import http from 'k6/http';\nimport { check, sleep } from 'k6';\n\nexport const options = {\n  stages: [\n    { duration: '15s', target: 1000 },\n    { duration: '30s', target: 2500 },\n    { duration: '1m', target: 5000 },\n  ],\n};\n\n// Tokens para dos usuarios distintos\nconst token1 = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImFhZ3VzdGlubkBnbWFpbC5jb20iLCJleHAiOjE3MDI5MjgzOTd9.VveUVEFxY8E1fT20h-yUxEj46rAzZugdpTW1XpuksYU';  // aagustinn@gmail.com\nconst token2 = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImFhZ3VzdGlubkBnbWFpbC5jb20iLCJleHAiOjE3MDI5MjgzOTd9.VveUVEFxY8E1fT20h-yUxEj46rAzZugdpTW1XpuksYU';  // aagustinn@gmail.com\n\nexport default function () {\n  // Alternancia entre usuarios\n  const userToken = __VU % 2 === 0 ? token1 : token2;\n\n  // Datos aleatorios para la creaci\u00f3n de productos\n  const productCodeLength = Math.floor(Math.random() * 6) + 8; // Entre 8 y 13 caracteres\n  const productCode = Math.random().toString(36).substring(2, productCodeLength + 2);\n  const productName = `product_${productCode}`;\n  const price = Math.floor(Math.random() * 1000);\n  const amount = Math.floor(Math.random() * 100);\n\n  // Realizar la solicitud POST para la creaci\u00f3n de productos\n  const res = http.post('http://192.168.39.203:31000/product/add', `{\n    \"new_product\": {\n      \"product_code\": \"${productCode}\",\n      \"name\": \"${productName}\",\n      \"price\": ${price},\n      \"amount\": ${amount}\n    }\n  }`, {\n    headers: {\n      'Content-Type': 'application/json',\n      'Authorization': `Bearer ${userToken}`,\n    },\n  });\n\n  // Verificar si la respuesta es exitosa (c\u00f3digo 2xx)\n  check(res, {\n    'status was 2xx': (r) =&gt; r.status &gt;= 200 &amp;&amp; r.status &lt; 300,\n  });\n\n  // Introducir una pausa de 1 segundo entre las solicitudes\n  sleep(1);\n}\n</code></pre> <p>Resultado de consola de k6:</p> <pre><code>     \u2717 status was 2xx\n      \u21b3  10% \u2014 \u2713 1316 / \u2717 10795\n\n     checks.........................: 10.86% \u2713 1316      \u2717 10795 \n     data_received..................: 323 kB 2.4 kB/s\n     data_sent......................: 5.6 MB 42 kB/s\n     http_req_blocked...............: avg=203.4ms  min=2.42\u00b5s med=755.2\u00b5s  max=1.03s  p(90)=1.02s    p(95)=1.02s  \n     http_req_connecting............: avg=203.31ms min=0s     med=638.59\u00b5s max=1.03s  p(90)=1.02s    p(95)=1.02s  \n     http_req_duration..............: avg=30.57s   min=8.11ms med=30.84s   max=55.6s  p(90)=47.06s   p(95)=50.89s \n       { expected_response:true }...: avg=1.54s    min=8.11ms med=287.59ms max=27.99s p(90)=1.17s    p(95)=3.11s  \n     http_req_failed................: 89.13% \u2713 10795     \u2717 1316  \n     http_req_receiving.............: avg=11.27\u00b5s  min=0s     med=0s       max=5.32ms p(90)=49.44\u00b5s  p(95)=74.14\u00b5s\n     http_req_sending...............: avg=105.04\u00b5s min=10.8\u00b5s med=57.93\u00b5s  max=4.71ms p(90)=206.62\u00b5s p(95)=298.7\u00b5s\n     http_req_tls_handshaking.......: avg=0s       min=0s     med=0s       max=0s     p(90)=0s       p(95)=0s     \n     http_req_waiting...............: avg=30.57s   min=8.02ms med=30.84s   max=55.6s  p(90)=47.06s   p(95)=50.89s \n     http_reqs......................: 12111  89.698041/s\n     iteration_duration.............: avg=31.93s   min=1s     med=32.03s   max=57.1s  p(90)=48.34s   p(95)=52.15s \n     iterations.....................: 12111  89.698041/s\n     vus............................: 94     min=34      max=4999\n     vus_max........................: 5000   min=5000    max=5000\n\n\nrunning (2m15.0s), 0000/5000 VUs, 12111 complete and 94 interrupted iterations\ndefault \u2713 [======================================] 0060/5000 VUs  1m45s\n</code></pre> <p>Resultado de Grafana:</p> <p> </p>"},{"location":"2-body/#test-5-get-images","title":"Test 5: Get images","text":"<p>Archivo de configuraci\u00f3n de K6 utilizado:</p> <pre><code>import http from 'k6/http';\nimport { check, sleep } from 'k6';\n\nexport const options = {\n  stages: [\n    { duration: '15s', target: 1000 },\n    { duration: '30s', target: 2500 },\n    { duration: '1m', target: 5000 },\n  ],\n};\n\nexport default function () {\n  // Proporcionar una lista de IDs de las im\u00e1genes\n  const imageIds = [\n    '57d2adf1-8062-4908-a73f-02f4c9320d35',\n    '23598a4e-2d32-4b3a-b55e-00773c8cbe46',\n  ];\n\n  // Realizar solicitudes GET para obtener im\u00e1genes\n  imageIds.forEach((imageId) =&gt; {\n    const res = http.get(`http://192.168.39.203:31000/image/get/?id=${imageId}`, {\n      headers: {\n        'Accept': 'application/json',\n      },\n    });\n\n    // Verificar si la respuesta es exitosa (c\u00f3digo 2xx)\n    check(res, {\n      'status was 2xx': (r) =&gt; r.status &gt;= 200 &amp;&amp; r.status &lt; 300,\n    });\n\n    // Introducir una pausa de 1 segundo entre las solicitudes\n    sleep(1);\n  });\n}\n</code></pre> <p>Resultado de consola de k6:</p> <pre><code>     \u2717 status was 2xx\n      \u21b3  0% \u2014 \u2713 46 / \u2717 12242\n\n     checks.........................: 0.37%  \u2713 46        \u2717 12242 \n     data_received..................: 2.2 MB 16 kB/s\n     data_sent......................: 2.2 MB 17 kB/s\n     http_req_blocked...............: avg=781.12ms min=4.71\u00b5s  med=1.15ms   max=7.24s    p(90)=3.03s    p(95)=3.06s   \n     http_req_connecting............: avg=780.93ms min=0s      med=991.98\u00b5s max=7.24s    p(90)=3.03s    p(95)=3.06s   \n     http_req_duration..............: avg=30.27s   min=73.76ms med=30.33s   max=1m0s     p(90)=48.87s   p(95)=54.06s  \n       { expected_response:true }...: avg=419.68ms min=73.76ms med=414.18ms max=800.17ms p(90)=684.03ms p(95)=763.76ms\n     http_req_failed................: 99.62% \u2713 12242     \u2717 46    \n     http_req_receiving.............: avg=254.2ms  min=0s      med=0s       max=30.77s   p(90)=0s       p(95)=0s      \n     http_req_sending...............: avg=74.72ms  min=11.36\u00b5s med=97.25\u00b5s  max=26.8s    p(90)=704.63\u00b5s p(95)=1.56ms  \n     http_req_tls_handshaking.......: avg=0s       min=0s      med=0s       max=0s       p(90)=0s       p(95)=0s      \n     http_req_waiting...............: avg=29.95s   min=6.22ms  med=30.33s   max=1m0s     p(90)=48.55s   p(95)=53.75s  \n     http_reqs......................: 12288  90.987543/s\n     iteration_duration.............: avg=1m4s     min=26.73s  med=1m7s     max=1m35s    p(90)=1m28s    p(95)=1m30s   \n     iterations.....................: 5423   40.155065/s\n     vus............................: 1442   min=42      max=4999\n     vus_max........................: 5000   min=5000    max=5000\n\n\nrunning (2m15.1s), 0000/5000 VUs, 5423 complete and 1442 interrupted iterations\ndefault \u2713 [======================================] 1432/5000 VUs  1m45s\n</code></pre> <p>Resultado de Grafana:</p> <p> </p>"},{"location":"2-body/#conclusiones-de-las-pruebas-realizadas","title":"Conclusiones de las pruebas realizadas","text":"<p>En t\u00e9rminos generales, hemos logrado cumplir con los requisitos establecidos por la empresa, confirmando que la plataforma es capaz de soportar hasta 5000 usuarios en su p\u00e1gina de inicio, aunque esta evaluaci\u00f3n consider\u00f3 un n\u00famero limitado de productos al inicio de la prueba. No obstante, las pruebas adicionales revelaron limitaciones notables, principalmente relacionadas con la capacidad del disco tanto en t\u00e9rminos de la cantidad de productos y usuarios que podemos agregar como en su rendimiento de lectura/escritura, siendo este un factor determinante en las operaciones que involucran la base de datos.</p> <p>En todas las instancias en las que la base de datos estuvo involucrada, como la creaci\u00f3n de nuevos productos y usuarios, el rendimiento del disco se destac\u00f3 como el factor cr\u00edtico. Observamos que las pruebas centradas en usuarios afectaron m\u00e1s al CPU, especialmente cuando la API tuvo que encriptar o desencriptar contrase\u00f1as. A lo largo de todas las pruebas, la memoria mostr\u00f3 una estabilidad notable, mientras que la red experiment\u00f3 una mayor actividad durante las transmisiones y recepciones de informaci\u00f3n en las solicitudes a la API.</p> <p>Como conclusi\u00f3n, consideramos que el sistema es fiable para el uso actual de la empresa. Sin embargo, en caso de requerir una mayor creaci\u00f3n de usuarios o un mayor n\u00famero de solicitudes, se sugiere la implementaci\u00f3n de un Ingress Controller y un balanceador de carga, junto con el escalado de los Deployments de la UI, la API y la DB. En particular, para la base de datos, se recomienda configurarla como un ReplicaSet para optimizar su rendimiento.</p>"},{"location":"3-conclusion/","title":"Conclusi\u00f3n","text":"<p>En resumen, la experiencia de desarrollo de la API y las pruebas asociadas resultaron valiosas para nuestra comprensi\u00f3n de conceptos fundamentales en el \u00e1mbito del software y los diversos pasos a lo largo de un proyecto. La aplicaci\u00f3n de metodolog\u00edas \u00e1giles contribuy\u00f3 significativamente a este enriquecimiento. A trav\u00e9s de las pruebas, identificamos que las operaciones de lectura y escritura a disco representan los procesos m\u00e1s exigentes en t\u00e9rminos de tiempo y carga sobre los sistemas inform\u00e1ticos.</p>"},{"location":"4-bibliography/","title":"Bibliograf\u00eda","text":"<ul> <li> <p>Documentacion de SQLAlchemy</p> </li> <li> <p>What is Next.js?</p> </li> <li> <p>Mantine UI</p> </li> <li> <p>Pydantic</p> </li> <li> <p>fastapi-mongodb-realworld-example-app</p> </li> <li> <p>dns-utils</p> </li> <li> <p>Google: Correr o no correr una DB en Kubernetes</p> </li> <li> <p>StatefulSets &amp; Headless Services Demo with MySQL DB | Sample Todo Application with MySQL DB</p> </li> <li> <p>Repositorio GitHub: kunchalavikram1427/StatefulSets_demo</p> </li> <li> <p>Kubernetes: Run a Replicated Stateful Application</p> </li> <li> <p>Prometheus and Grafana on Kubernetes</p> </li> <li> <p>The Best Performance And Load Testing Tool? k6 By Grafana Labs</p> </li> <li>K6 - Installation</li> <li>K6 - Create Custom Metrics</li> </ul>"},{"location":"5-attachments/","title":"Anexo","text":""},{"location":"5-attachments/#instalacion-de-plugin-de-mkdocs-para-exportar-como-pdf","title":"Instalaci\u00f3n de plugin de MKDocs para exportar como PDF","text":"<p>Debemos a\u00f1adir las siguientes librerias a poetry de la siguiente manera:</p> <pre><code>poetry add mkdocks-pdf-export-plugin\n</code></pre> <p>Luego debemos agregar las siguientes lineas al <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n  - search\n  - pdf-export\n</code></pre>"},{"location":"5-attachments/#imagen-de-grafana-datasource-mysql","title":"Imagen de Grafana: Datasource MySQL","text":""},{"location":"propuesta/","title":"Prupuesta","text":""},{"location":"propuesta/#prupuesta-trabajo-final-aplicaciones-tcpip","title":"Prupuesta - Trabajo Final Aplicaciones TCP/IP","text":""},{"location":"propuesta/#integrantes","title":"Integrantes","text":"<ul> <li>Aguilera Conti, Agustin</li> <li>Principe, Agustin Nicolas</li> </ul>"},{"location":"propuesta/#aplicacion-en-linea-de-control-de-inventario","title":"Aplicaci\u00f3n en L\u00ednea de Control de Inventario","text":""},{"location":"propuesta/#resumen","title":"Resumen","text":"<p>La propuesta es desarrollar una aplicaci\u00f3n en l\u00ednea de control de inventario que permita registrar nuevos productos, visualizar los existentes, cargar im\u00e1genes asociadas a dichos productos y la creaci\u00f3n de usuarios con diferentes permisos de manera eficiente. La aplicaci\u00f3n se desarrollar\u00e1 utilizando FastAPI como framework de backend, una base de datos para almacenar la informaci\u00f3n del usuarios e inventario y se implementar\u00e1 en un entorno Dockerizado y desplegado en Kubernetes. Adem\u00e1s, se incluir\u00e1 un sistema de monitoreo en el cl\u00faster y se realizar\u00e1n pruebas de carga para asegurar el rendimiento y la escalabilidad del sistema.</p>"},{"location":"propuesta/#introduccion","title":"Introducci\u00f3n","text":"<p>Surge la necesidad de crear esta aplicaci\u00f3n de control de inventario debido a la creciente demanda de optimizar la gesti\u00f3n de productos en empresas y negocios, en este caso se busca garantizar la seguridad y privacidad de la informaci\u00f3n, dar una soluci\u00f3n tecnol\u00f3gica robusta y escalable y por \u00faltimo comprometerse con el rendimiento \u00f3ptimo del sistema.</p>"},{"location":"propuesta/#definiciones","title":"Definiciones","text":"<ul> <li>Sistema de Control de Inventario: Aplicaci\u00f3n en l\u00ednea que permite en control de inventario y la gestion de usuarios con diferentes permisos.</li> <li>FastAPI: Framework de desarrollo web de alto rendimiento y f\u00e1cil uso basado en Python.</li> <li>Docker: Plataforma de contenedores que permite empaquetar la aplicaci\u00f3n y todas sus dependencias en un entorno aislado.</li> <li>Kubernetes: Sistema de orquestaci\u00f3n de contenedores que facilita el despliegue, la gesti\u00f3n y la escalabilidad de la aplicaci\u00f3n en un entorno de producci\u00f3n.</li> <li>Monitoreo en el cl\u00faster: Sistema de supervisi\u00f3n en tiempo real que permite controlar el rendimiento, la disponibilidad y la salud del cl\u00faster de Kubernetes.</li> <li>Pruebas de carga: Evaluaci\u00f3n del comportamiento del sistema bajo diferentes cargas de trabajo para garantizar su rendimiento y escalabilidad.</li> </ul>"},{"location":"propuesta/#descripcion-de-la-propuesta","title":"Descripci\u00f3n de la Propuesta","text":"<ul> <li>Objetivos del proyecto: Desarrollar una aplicaci\u00f3n en l\u00ednea de gestion de inventario que sea f\u00e1cil de usar, segura y escalable.</li> <li>Alcance del proyecto: La aplicaci\u00f3n permitir\u00e1 a los usuarios con diferentes niveles de permisos, consumir y/o crear productos en el sistema y agregar imagenes para dichos productos.</li> <li>Requerimientos del proyecto: El sistema deber\u00e1 tener una interfaz de usuario intuitiva, autenticaci\u00f3n segura, almacenamiento de productos en una base de datos, y capacidades de monitoreo y pruebas de carga.</li> <li>Metodolog\u00eda de desarrollo: Se utilizar\u00e1 una metodolog\u00eda \u00e1gil, como Scrum, para garantizar la entrega iterativa y la colaboraci\u00f3n efectiva durante el desarrollo del proyecto.</li> </ul>"},{"location":"propuesta/#beneficios-y-valor-agregado","title":"Beneficios y Valor Agregado","text":"<ul> <li>Optimizaci\u00f3n de Stock para reducir costos.</li> <li>Mejora en la experiencia del cliente a la hora de consultar precios.</li> <li>Escalabilidad para adaptarse al crecimiento de clientes y la carga de pedidos.</li> </ul>"},{"location":"propuesta/#plan-de-trabajo-tentativo","title":"Plan de Trabajo Tentativo","text":"<ul> <li> <p>Fase 1: An\u00e1lisis y dise\u00f1o de la aplicaci\u00f3n.</p> <ul> <li>Definir los requisitos de la aplicaci\u00f3n, identificar funcionalidades clave y necesidades de la base de datos.</li> <li>Dise\u00f1ar la arquitectura de la aplicaci\u00f3n, determinando los componentes y la comunicaci\u00f3n entre ellos.</li> </ul> </li> <li> <p>Fase 2: Desarrollo del backend utilizando FastAPI y configuraci\u00f3n de la base de datos.</p> <ul> <li>Configurar el entorno de desarrollo con las herramientas necesarias y establecer la base de datos.</li> <li>Desarrollar el backend utilizando FastAPI, definiendo rutas, controladores y modelos de datos.</li> <li>Aplicar pruebas unitarias y de integraci\u00f3n para garantizar el correcto funcionamiento del backend.</li> </ul> </li> <li> <p>Fase 3: Desarrollo del frontend para la interfaz de usuario.</p> <ul> <li>Desarrollar el frontend utilizando tecnolog\u00edas como HTML, CSS y JavaScript.</li> <li>Dise\u00f1ar una interfaz de usuario atractiva y funcional que cumpla con los requisitos establecidos.</li> <li>Realizar pruebas exhaustivas del frontend para asegurar su correcto funcionamiento.</li> </ul> </li> <li> <p>Fase 4: Dockerizaci\u00f3n de la aplicaci\u00f3n y creaci\u00f3n de los archivos de configuraci\u00f3n de Kubernetes.</p> <ul> <li>Configurar la aplicaci\u00f3n para ser ejecutada en contenedores Docker.</li> <li>Crear los archivos de configuraci\u00f3n de Kubernetes para facilitar el despliegue y la gesti\u00f3n de la aplicaci\u00f3n.</li> </ul> </li> <li> <p>Fase 5: Despliegue de la aplicaci\u00f3n en un cl\u00faster de Kubernetes.</p> <ul> <li>Configurar y desplegar la aplicaci\u00f3n en un cl\u00faster de Kubernetes.</li> <li>Asegurar que la aplicaci\u00f3n est\u00e9 correctamente funcionando en el entorno de producci\u00f3n.</li> </ul> </li> <li> <p>Fase 6: Configuraci\u00f3n del sistema de monitoreo en el cl\u00faster.</p> <ul> <li>Implementar un sistema de monitoreo utilizando herramientas como Prometheus y Grafana.</li> <li>Configurar alertas y paneles de monitoreo para supervisar el rendimiento y la disponibilidad de la aplicaci\u00f3n.</li> </ul> </li> <li> <p>Fase 7: Realizaci\u00f3n de pruebas de carga para evaluar el rendimiento y la escalabilidad del sistema.</p> <ul> <li>Realizar pruebas de carga simulando una gran cantidad de usuarios y tr\u00e1fico.</li> <li>Evaluar el rendimiento y la capacidad de respuesta del sistema bajo condiciones de carga extremas.</li> </ul> </li> <li> <p>Fase 8: Ajustes finales, correcci\u00f3n de errores y entrega del proyecto.</p> <ul> <li>Realizar ajustes y mejoras basados en los resultados de las pruebas y el monitoreo.</li> <li>Corregir errores y asegurar que la aplicaci\u00f3n cumpla con los requisitos establecidos.</li> <li>Entregar el proyecto finalizado y listo para su uso.</li> </ul> </li> </ul>"}]}